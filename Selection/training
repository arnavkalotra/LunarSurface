import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from torch import nn, optim
from tqdm import tqdm
from skimage.transform import resize
from scipy.ndimage import generic_filter, gaussian_filter
import rasterio
from rasterio.transform import Affine

# Dataset Class
class ElevationSuperResDataset(Dataset):
    def __init__(self, tif_path, patch_size=64, scale=2, max_nan_pct=0.05):
        with rasterio.open(tif_path) as src:
            self.hr_raw = src.read(1).astype(np.float32)
            self.transform = src.transform
            self.crs = src.crs

        self.mask = np.isnan(self.hr_raw)
        self.hr_filled = self._fill_nan_local_median(self.hr_raw, ksize=3)
        smoothed = gaussian_filter(self.hr_filled, sigma=0.5)

        self.min_val = np.nanmin(smoothed)
        self.max_val = np.nanmax(smoothed)
        self.hr = (smoothed - self.min_val) / (self.max_val - self.min_val)
        self.lr = resize(self.hr, (self.hr.shape[0] // scale, self.hr.shape[1] // scale), anti_aliasing=True)

        self.scale = scale
        self.patch_size = patch_size
        self.max_nan_pct = max_nan_pct

    def _fill_nan_local_median(self, array, ksize=5):
        def nanmedian_filter(values):
            v = values[~np.isnan(values)]
            return np.median(v) if v.size > 0 else 0.0
        return generic_filter(array, nanmedian_filter, size=ksize, mode='reflect')

    def __len__(self):
        return 1000

    def __getitem__(self, idx):
        for _ in range(10):
            x = np.random.randint(0, self.lr.shape[0] - self.patch_size)
            y = np.random.randint(0, self.lr.shape[1] - self.patch_size)
            x_hr, y_hr = x * self.scale, y * self.scale
            hr_patch = self.hr[x_hr:x_hr + self.patch_size * self.scale,
                               y_hr:y_hr + self.patch_size * self.scale]
            if np.isnan(hr_patch).mean() < self.max_nan_pct:
                break
        lr_patch = self.lr[x:x + self.patch_size, y:y + self.patch_size]
        return torch.from_numpy(lr_patch).float().unsqueeze(0), torch.from_numpy(hr_patch).float().unsqueeze(0)

# Elevation-Aware Loss
class ElevationGradientLoss(nn.Module):
    def forward(self, pred, target):
        pred_dx = pred[:, :, :, 1:] - pred[:, :, :, :-1]
        pred_dy = pred[:, :, 1:, :] - pred[:, :, :-1, :]
        target_dx = target[:, :, :, 1:] - target[:, :, :, :-1]
        target_dy = target[:, :, 1:, :] - target[:, :, :-1, :]
        grad_loss = (pred_dx - target_dx).abs().mean() + (pred_dy - target_dy).abs().mean()
        l1_loss = (pred - target).abs().mean()
        return l1_loss + 0.5 * grad_loss

# Inference with Edge-Aware Patching and Pixel Metadata Fix
@torch.no_grad()
def infer_full_resolution(model, dataset, output_path='super_res_output.tif', patch_size=128, overlap=16):
    device = next(model.parameters()).device
    model.eval()

    lr = dataset.lr
    h_lr, w_lr = lr.shape
    scale = dataset.scale
    h_hr, w_hr = h_lr * scale, w_lr * scale

    sr_full = np.zeros((h_hr, w_hr), dtype=np.float32)
    sr_count = np.zeros((h_hr, w_hr), dtype=np.float32)

    step = patch_size - overlap
    for i in tqdm(range(0, h_lr, step), desc="Full Inference"):
        for j in range(0, w_lr, step):
            i_end = min(i + patch_size, h_lr)
            j_end = min(j + patch_size, w_lr)

            lr_patch = lr[i:i_end, j:j_end]

            pad_h = patch_size - (i_end - i)
            pad_w = patch_size - (j_end - j)
            if pad_h > 0 or pad_w > 0:
                lr_patch = np.pad(lr_patch, ((0, pad_h), (0, pad_w)), mode='reflect')

            lr_tensor = torch.from_numpy(lr_patch).unsqueeze(0).unsqueeze(0).float().to(device)
            sr_patch = model(lr_tensor).squeeze().cpu().numpy()

            x_hr, y_hr = i * scale, j * scale
            ph, pw = (i_end - i) * scale, (j_end - j) * scale

            sr_full[x_hr:x_hr+ph, y_hr:y_hr+pw] += sr_patch[:ph, :pw]
            sr_count[x_hr:x_hr+ph, y_hr:y_hr+pw] += 1

    sr_full = sr_full / np.maximum(sr_count, 1)
    sr_denorm = sr_full * (dataset.max_val - dataset.min_val) + dataset.min_val
    sr_denorm = np.clip(sr_denorm, dataset.min_val, dataset.max_val)

    original_transform = dataset.transform
    new_transform = Affine(
        original_transform.a / scale, original_transform.b, original_transform.c,
        original_transform.d, original_transform.e / scale, original_transform.f
    )

    with rasterio.open(
        output_path, 'w', driver='GTiff', height=sr_denorm.shape[0], width=sr_denorm.shape[1],
        count=1, dtype=sr_denorm.dtype, crs=dataset.crs, transform=new_transform
    ) as dst:
        dst.write(sr_denorm, 1)

    print(f"Saved corrected super-resolved GeoTIFF to: {output_path}")

# Main Training + Inference

def train_and_infer():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    dataset = ElevationSuperResDataset("elevation_test.tif", patch_size=64)
    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

    model = SwinIR(
        upscale=2,
        in_chans=1,
        img_size=64,
        window_size=8,
        img_range=1.0,
        depths=[6, 6, 6, 6],
        embed_dim=60,
        num_heads=[6, 6, 6, 6],
        mlp_ratio=2,
        upsampler='pixelshuffle',
        resi_connection='1conv'
    ).to(device)

    criterion = ElevationGradientLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    for epoch in range(40):
        model.train()
        total_loss = 0
        for lr, hr in tqdm(dataloader, desc=f"Epoch {epoch+1}/40"):
            lr, hr = lr.to(device), hr.to(device)
            sr = model(lr)
            loss = criterion(sr, hr)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch {epoch+1} Loss: {total_loss:.4f}")

    infer_full_resolution(model, dataset)

if __name__ == '__main__':
    train_and_infer()
